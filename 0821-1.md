# 教材
[video](https://www.youtube.com/playlist?list=PL1f_B9coMEeC38AHRAP2XnoffkoCEFV4K)

# 模型調整
1. input前處理

順序資料 LabelEncoder\
類別資料 One-hot Encoding 但會 sparse\
re-scale 數值資料: 改變單位使單位一致, 因為不同的scale需要不同的learning-rate, 相同的scale可以讓結果收斂較快
re-scale就是作正規化\
在 dnn 裡面每次的 scale 都不同(internal covariate shift 問題), 需要對每一層做正規化, 常見的方法有
* batch-norm
  * 使用 beta & gamma (使用 GD 學習, 非 hyper-parameter)避免每次 norm 後把前面的學習結果消除\
在測試階段做\
測試資料沒有batch的概念, 其所需的 avg 跟 std 來自訓練資料但直接計算每層的 avg 跟 std 很難算\
折衷方法是分別計算每個batch的移動平均拿來當作 avg 跟 std\

* 常見的 activation function

regression:\
sigmoid、tanh、relu、elu、leaky relu、maxout
因為tanh/sigmoid當輸入為極值的時候很有可能會讓learning rate很低導致梯度消失的問題\
relu則是輸入小於0時, 輸出為0, 網路就不更新了, 所以才有softplus/leaky relu的出現\
分類問題的激發函數:\
softmax, 其 output 為 1, 類似機率, 方便做loss的更新, 因為會保留其他類別的預測錯誤
* 常見的 loss function
[regression]\
mse, mae, mape, msle, rmse
[classification]\
binary crossentropy
categorical corssentropy:
要將class改為one-hot encoding
`keras.np_utils.to_category(input)`

挑選原則
分類用 cross-entropy 搭配輸出層用 softmax
回歸用 mae / mse
特定問題可定義特殊的loss function, 比如說針對分類客製化f1-score, 針對回歸客製化r2score, 針對 unbalanced dataset 定義 penalty(比如說警察抓小偷問題, 小偷很少,  把正常人猜成小偷就給予大懲罰)
* 常用的optimizer(如何學習的方法)
SGD
Adgard: adaptive learning rate(learning rate會依據情況改變, 比如說當input沒做re-scale的時候)
RMSprop: another adaptive learning rate(避免越接近minimal的時候跳走, 所以learning-rate逐層降低)
Adam: RMSprop + momentum(慣性定律), 效果不錯
Nadam: Adam + nesterove momentum

調整參數的方法
1. 改變 activate function
2. 改變 learning-rate
3. 改變 optimizer

