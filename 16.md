# Logistic regression
線性迴歸: 找到y=ax+b使其SSE最小
腫瘤問題
很容易受極值影響預測結果
使用S-shaped function避免
1. [logistic function](https://zh.wikipedia.org/wiki/S%E5%87%BD%E6%95%B0)
結果為0 ~ 1, 使用 cross entropy loss
2. tanh function
結果為-1 ~ 1
* likelihood
* why use log-likelihood
1. 相加比相乘快
2. 相乘很快會underflow
* how to find theta to make log-likelihood maximum
GD(修改函數為相減)
GA(與GD相反)
多個分類用 softmax function

## summary
用 likelihood function 做回歸的方式解分類問題
最大化log-likelihood = 最小化 -log-likelihood
linear regression 最小化SSE
logistic regression 最小化 cross entry loss

### quiz
* what is logistic regression?
做分類的方法, 底層是回歸, 找到 theta 最大化log-likelihood or 最小化 cross entropy loss
* why maximum log-likelihood function?
每一筆資料都是介於0-1, 相乘的話很快會underflow, 改為log-likelihood 相加可避免此問題, 且其為漸增, 因此theta的結果不會因 log 有差異
* what is [cross entropy loss](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E4%BB%8B%E7%B4%B9-%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-loss-function-2dcac5ebb6cb)?
衡量 binary 分類的 test 做的有多差的指標, 其值為 -(log-likelihood)

## [評估分類指標](https://www.youtube.com/watch?v=ITX-NsE01Aw&list=PL1f_B9coMEeB0uxQwlKLGGyDpI_Xs8iCY&index=10)
### accuracy
100w testing, 90w good, 10w error => 90 / 100 = 0.9\
is 0.5 a good accuracy? 如果是binary就是差的\
is 0.9 a good accuracy? 如果是binary是好的, 但如果比例懸殊則很差\
is 0.1 a good accuracy?
主要看群體數的比例
### precision
* confusion matrix(type I, type II)\
![]('../notes/imgs/16-01.png')
tp: true positive, y=1 & predict=1 \
fp: false positive, y=1 & predict=0 \
fn: false negative, y=0 & predict=1 \
tn: true negative, y=0 & predict=0 \
tp / (tp+fp), 常用來作為搜尋引擎的結果好壞
### recall
tp/(tp+fn), A.K.A TP-Rate, 常用在醫療領域
與precision之間會有tradeoff(一高一低)
### f score
同時考慮precision跟recall\
(1 + beta^2) * (precision * recall) / (beta^2)(precision + recall)\
beta=1則叫做 f1-score
### precision recall curve
通常 precision 高 recall 低, 互斥
### ROC curve and AUC(area under curve)
* ROC
tp-rate & fp-rate(fp/(fp+tn))間的關係
依不同的門檻計算 tpr, fpr 並把其繪製呈現
好處是不管正負樣本比例是否懸殊, 出來的結果都差不多
永遠猜major的類別的話會得到對角線(AUC=0.5)
* AUC
在繪製出來的ROC底下的面積大小
pros:
樣本比例懸殊的時候得到的結果仍會差不多, 且 AUC <= 0.5 的話表示模型(function)不正確
