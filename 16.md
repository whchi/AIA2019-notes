# Logistic regression
線性迴歸: 找到y=ax+b使其SSE最小
腫瘤問題
很容易受極值影響預測結果
使用S-shaped function避免
1. logistic function
結果為0 ~ 1, 使用 cross entropy loss
2. tanh function
結果為-1 ~ 1
* likelihood
* why use log-likelihood
1. 相加比相乘快
2. 相乘很快會underflow
* how to find theta to make log-likelihood maximum
GD(修改函數為相減)
GA(與GD相反)
多個分類用 softmax function

## summary
用 likelihood function 做回歸的方式解分類問題
最大化log-likelihood = 最小化 -log-likelihood
linear regression 最小化SSE
logistic regression 最小化 cross entry loss

### quiz
* what is logistic regression?
做分類的方法, 底層是回歸, 找到 theta 最大化log-likelihood or 最小化 cross entropy loss
* why maximum log-likelihood function?
每一筆資料都是介於0-1, 相乘的話很快會underflow, 改為log-likelihood 相加可避免此問題, 且其為漸增, 因此theta的結果不會因 log 有差異
* what is cross entropy loss?
衡量 binary 分類的 test 做的有多差的指標, 其值為 -(log-likelihood)

## [評估分類指標](https://www.youtube.com/watch?v=ITX-NsE01Aw&list=PL1f_B9coMEeB0uxQwlKLGGyDpI_Xs8iCY&index=10)
### accuracy
100w testing, 90w good, 10w error => 90 / 100 = 0.9\
is 0.5 a good accuracy? 如果是binary就是差的\
is 0.9 a good accuracy? 如果是binary是好的, 但如果比例懸殊則很差\
is 0.1 a good accuracy?
主要看群體數的比例
### precision
* confusion matrix(type I, type II)\
![]('../notes/imgs/16-01.png')
tp: true positive, y=1 & predict=1 \
fp: false positive, y=1 & predict=0 \
fn: false negative, y=0 & predict=1 \
tn: true negative, y=0 & predict=0 \
tp / (tp+fp), 常用來作為搜尋引擎的結果好壞
### recall
tp/(tp+fn), A.K.A TPR, 常用在醫療領域
與precision之間會有tradeoff(一高一低)
### f1 score
同時考慮precision跟recall
2(pr) / (p+r)
* F-beta score
### precision recall curve
p高,r低
### ROC curve and AUC(area under curve)
* ROC
tp-rate & fp-rate(fp/(fp+tn))間的關係
依不同的門檻計算 tpr, fpr 並把其繪製呈現
* AUC
在繪製出來的ROC底下的面積大小
pros:
樣本比例懸殊的時候得到的結果仍會差不多, 且 AUC < 0.5 的話表示模型(function)不正確
