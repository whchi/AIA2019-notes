# 教材
* [ppt](https://docs.google.com/presentation/d/1gEGwBNvDF1zphKp__wLxGbaaUANE2UOTORG5y8fM8hs/edit#slide=id.p1)
* [video](https://www.youtube.com/playlist?list=PL1f_B9coMEeB0uxQwlKLGGyDpI_Xs8iCY)
* [15](15.md)
* [16](16.md)
* [17](17.md)
# KNN
不用 tarining time\
找出最靠近預測值的K個點, 並依K個點分布的群體決定預測值所屬的群體
通常要做feature norm(scale to [0, 1], [-1, 1], norm to N[0, 1])
## 選擇K
找出training error跟test error交界點
## [pros and cons](https://www.youtube.com/watch?v=pbcIPPXJC2Q&list=PL1f_B9coMEeB0uxQwlKLGGyDpI_Xs8iCY&index=5)

# logistic regression
解分類問題
找到theta使得log-likelihood, 同時也是使得cross entropy loss(- log-likelihood) 最小
## summary
解分類問題, model成 likelihood function 取 log 計算使得log-likelihood function 最大(cross entropy loss最小化)

# 評估模型指標
accuracy 對所有的y與預測的y是否一致
## confusion matrix
type I, type II matrix
# summary
|logistic|linear|
|:--|:--|
|分類問題|連續值|
|c越大控制力越弱|alpha越大控制力越強|
# threshold
比較可能出現 threshold up, precision up, recall down
logistic regession 的 data 的 threshold, 設為0.5則為進行二元分類, 調整其數值已得到不同的f1-score
* when to use precision-recall or ROC\
如果很重視recall(樣本比例差異很大的分類/detection問題, 比如說警察抓小偷關心的是小偷的比例, 不管他比例是否比較低)時用前者
