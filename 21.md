# [regularize linear regression](https://www.youtube.com/watch?v=GwLzpDmBke8&list=PL1f_B9coMEeCvbetNGYmW7fWUBSo0-D_i&index=4)

SVM: 最大化margin, 使用soft margin or kernel trick
logistic regresson: 最大化log-likelihood or 最小化 crossentropyloss, 使用GA or GD

使用 hinge loss 等於 SVM, 使用 logistic loss 等於 logistic regression

* summary\
通常說到 SVM 都是指 kernel SVM, 但其實還是有 linear 的 SVM
通常說到 logistic regression 則為 linear, 但可以做 kernel, 不過很少用

kernel(linear) SVM , kernel(linear) logistic regression 效果差不多
