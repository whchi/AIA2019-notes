# python
[numpy rules of broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)
* Rule 1: If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.
* Rule 2: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.
* Rule 3: If in any dimension the sizes disagree and neither is equal to 1, an error is raised.
* why list, dict, tuple, set
data structure 以 order, mutability切分成四個象限, 分別符合4個象限
* loc vs iloc
都是 [row, col], 只差在用label or index, row/col 可以用跟list一樣的方式取
* [iteratir & generator](https://nvie.com/posts/iterators-vs-generators/)

# 機率與統計
* 離群值處理
[z-score](https://zh.wikipedia.org/wiki/%E6%A8%99%E6%BA%96%E5%88%86%E6%95%B8) or 每次只剔除一個點, 看每次的殘差, 把殘差最大排除
* 距離與相似度量測
相關係數: pearson, spearman rank, kendall's tau\
相似度: cos, distance, correlation\
相關不等於有關\
比如說大象跟螞蟻的體重都可能可以用同樣的模型處理, 但兩者的單位數不同, 因此要把單位因素消除, 避免輸入參數影響模型計算結果\
**補充**\
算出來的 cov 是屬於變數跟變數間的還是樣本跟樣本間的


* 大數法則&中央極限定理
**補充**\
母體平均數(or 變異數, 大數法則不用)是否有限且存在\
iid: 獨立且服從同分佈\
樣本平均數的收斂數
* 區間估計
* 假設檢定
**補充**\
不能夠在不改變樣本的狀況下同時下降 type I, type II 的機率\
alpha = P(type I);beta = P(type II), 混淆矩陣就是在講這個
* 無母數統計
目的不是為了確認母體跟抽樣的分佈/差值是否一致, 而是當未知母體的時候, 要怎麼進行檢定．\
比如說當母體未知的時候, 不能用平均數反而要用中位數進行單點檢定
* 必須正確的觀念
1. 資料描述
2. 距離與相似度量測: 需要依照資料類型相關係數, 尺度轉換(特徵工程)
3. 大數法則/中央極限定理
4. 信賴區間(相對簡單)
5. 假設檢定

統計與機器學習的關聯性?\
懂統計的話可以在不同維度找出看似無相關的資料, 善用資料前處理跟觀察\
相關不等於有關: 年齡、髮量、身體素質(隱藏變數), 隱藏變數要靠領域知識尋找, 統計領域有個中介變數處理這件事情

機器學習的經典算法通常是基於常態分配的假設, 因此資料是否是常態分佈對算法結果影響很大, 假如資料不符合常態分佈的話有幾個解決方式 (1)資料處理 (2)變換算法模型, 而不是反過來說機器學習是要追求常態分佈
