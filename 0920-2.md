# RNN part2
[video](https://www.youtube.com/playlist?list=PL1f_B9coMEeATcBup_lNZh5u7ZrODW4FO)

# keras實戰情意分析
RNN也可以用1d cnn訓練

用RNN做翻譯很類似對話機器人, 把前幾句話濃縮成一個向量(h), 這樣不太合理, 應該是考量比較重要的h是哪些再去做
> The fall of RNN / LSTM
> Attention Is All You Need

# recap
* 平均值等同於在計算某隨機變數的期望值
* 變異數為計算每個數質與平均值的距離(平方差的平均值)
Var(X + Y) = Var(X) + Var(Y)
如果X, Y獨立且平均值為0, 則 Var(XY) = Var(X) Var(Y)
* 標準差為變異數開根號
所以 X 的變異數常寫為 標準差^2
標準常態分佈是平均值為0, 變異數為1的常態分佈
使用numpy取上面幾個東西計算
np.random.randn(n_samples=n): 從標準常態分佈抽n個數字
平均值改a,標準差改b: randn(n) * b + a
相反的, 改回常態分佈: (randn(n) - a)/b
