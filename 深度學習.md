# notes
[0816](0816.md)
ontology->BDI Agent
how machine learning? guess, adjust
強化學習: learn from environment, 猜錯懲罰
bias可視為閘值
[xor問題](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-%E5%A4%9A%E5%B1%A4%E6%84%9F%E7%9F%A5%E6%A9%9F-multilayer-perceptron-mlp-%E9%81%8B%E4%BD%9C%E6%96%B9%E5%BC%8F-f0e108e8b9af)
[0817-1](0817-1.md)
GD: 找出 function中斜率的最低點(local minimal)
透過BP取得梯度, 進行GD取得最小化loss的weight, 最後找出的公式為預測公式
梯度消失: 覺得已經學到底了就不再調整w, 可用慣性定律克服
[0817-2](0817-2.md)
tensorflow
graph: 設計圖
session: 插電
placeholder: 神經網路的框框
naming: 取值的時候很重要
每次的variable都要init後才能用
sess.run跑tensor
scope
[0821-1](0821-1.md)
# model tuning
DL使用的必須為數值,
1. 順序行可用label-encoding, 類別行可用one-hot encoding
2. input data re-scale(單位修正(log / mean...), 減少loss)\
數值正規化, 在實務上會有 internal covariate shift問題, 雖然減少 learning rate可減緩此問題但會讓訓練變慢, 所以可用 batch norm 解決此問題
norm: 平均值為 0 標準差為 1, 實務上會加上 beta & gamma 避免每次norm完的結果都被縮限到一個範圍內導致結果不變
可減少梯度消失 / 爆炸的問題
越簡單的使用 RMSprop 比較快, Adam可能會過頭再回來, SGD/momentum 會跳來跳去
越複雜的用 Adam
[0821-2](0821-2.md)
# 避免 overfitting
