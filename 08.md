# 資料轉換

why:
1. 讓轉換後的資料偏向常態分佈
2. 增加解釋性
3. 增加理解程度
4. 可以互相比較
5. 偏向線性叫好解釋
6. 修改weights
7. 比較好code
比如說把性別 / 專長改為數值
how:
指數轉換
對數轉換: 資料必須都是正的, 若有負值則 log(x+1-min(x)), 但也有另一派認為應該視為缺失值
開根號*10
截斷轉換
可用apply對矩陣內所有資料轉換
[box-cox](https://baike.baidu.com/item/Box-Cox%E5%8F%98%E6%8D%A2/10278422): 不適合雙峰或U型

## [標準化](https://zh.wikipedia.org/wiki/%E6%A0%87%E5%87%86%E5%8C%96_(%E7%BB%9F%E8%AE%A1%E5%AD%A6))
(xi - avg(x)) / sd
將資料表的每個變數做標準化, 讓所有變數的單位平均為0, 變異數為1, 避免極值影響分析結果, 不會影響分佈
資料的轉換方式來自資料的背景知識

# 重抽

why:
整合學習(較好的預測能力、較穩定)
how:
[交互驗證法](https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89)

* [Leave-one-out 法則](https://medium.com/@chih.sheng.huang821/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89-cross-validation-cv-3b2c714b18db)

[集成學習方法比較](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-ensemble-learning%E4%B9%8Bbagging-boosting%E5%92%8Cadaboost-af031229ebc3)
* [拔靴法](https://baike.baidu.com/item/%E6%8B%94%E9%9D%B4%E6%B3%95): 對樣本不斷重抽放回直到樣本個數等於母體數, 依此取得抽樣分佈
* [bagging(bootstrap aggreating)](https://zh.wikipedia.org/wiki/Bagging%E7%AE%97%E6%B3%95)
* [boosting](https://zh.wikipedia.org/wiki/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95)

## 不平衡資料處理
what: 有興趣的觀察類別總量小於另外一種類別的資料, 比如說觀察詐騙交易, 但只佔總量的5%
有兩種處理方式: over-sampling(增加有興趣的資料), under-sampling(減少無興趣的資料), 套件都有實作
處理方法有ubCNN、ubENN、ubNCL、ubTomek、ubOSS、ubSMOTE等，不過最省事的方法是利用ubRacing
